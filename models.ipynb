{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9851c01e",
   "metadata": {},
   "source": [
    "# Setting up environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e93a558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pymongo import MongoClient\n",
    "from passwords import password"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e963e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "def evaluate_predictions(predictions):\n",
    "    counter=0\n",
    "    for pred in predictions:\n",
    "        print(f'The sentence \"{sentences[counter]}\" is {pred}')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a212f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to MongoDB\n",
    "\n",
    "# Initialize authentication & cursor variables\n",
    "mongo_uri = f'mongodb+srv://kkosek:{password}@cluster0.lv4rmyj.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
    "db_name = 'walmart'\n",
    "collection_name = 'scraper'\n",
    "\n",
    "# Create a client\n",
    "client = MongoClient(mongo_uri)\n",
    "# Connect to the 'walmart' database\n",
    "db = client[db_name]  \n",
    "# Open the 'scraper' collection\n",
    "collection = db[collection_name] \n",
    "\n",
    "# Fetch all documents from the collection\n",
    "cursor = collection.find({})\n",
    "\n",
    "# Convert documents to a list of dictionaries\n",
    "documents = list(cursor)\n",
    "\n",
    "# Close the cursor and client\n",
    "cursor.close()\n",
    "client.close()\n",
    "\n",
    "# Convert the list of dicts to master DataFrame\n",
    "df = pd.DataFrame(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e942f",
   "metadata": {},
   "source": [
    "# Establishing Purpose\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f71d46",
   "metadata": {},
   "source": [
    "For the purpose of this project, we want to utilize our webscraped Walmart product review dataset to train an NLP model to categorize various ranges of sentiment based only on the textual data of the review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "057c19b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Here we visualize the distribution of n-star reviews in the dataset\n",
    "ax = df['stars'].value_counts().sort_index() \\\n",
    "    .plot(kind='bar',\n",
    "          title='Count of Reviews by Stars',\n",
    "          figsize=(10, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe1e6fc3",
   "metadata": {},
   "source": [
    "# Binary Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41e2e08",
   "metadata": {},
   "source": [
    "In this simple model, we construct a pipeline for tokenizing, vectorizing, and classifying binary sentiment. We will extract only the 5 star and 1 star reviews from the full dataset and label all 5-star reviews as positive sentiment & all 1-star reviews as negative sentiment. Once the data has been preprocessed, we fit the data onto our Pipeline object and make some predictions. We utilize a naive Bayes prediction model for classification of the text for simplicity. Although other models achieve slightly higher accuracies, the naive Bayes is computationally miniature and achieving a significant accuracy already. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f48586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Preprocess\n",
    "\n",
    "# Create copy of master df\n",
    "binary_df = df.copy()\n",
    "# Create a copy of the 'stars' column where 'stars' is equal to 5\n",
    "five = binary_df.loc[ binary_df['stars'] == 5 ].copy()\n",
    "# Add a new column in the length of the DataFrame with all 1s to bin 5stars\n",
    "five['bin_sent'] = pd.Series( [x/x for x in range(1,len(five)+1)] , index=five.index )\n",
    "# Create a copy of the 'stars' column where 'stars' is equal to 1\n",
    "one = binary_df.loc[ binary_df['stars'] == 1 ].copy()\n",
    "# Add a new column in the length of the DataFrame with all 0s to bin 1stars\n",
    "one['bin_sent'] = pd.Series( [((x/x)-1) for x in range(1,len(one)+1)] , index=one.index )\n",
    "# Concat the binary sentiment df\n",
    "pos_neg = pd.concat( [five,one] )\n",
    "\n",
    "# Separate df into data & target\n",
    "binary_data = np.array(pos_neg['text'])\n",
    "binary_target = np.array(pos_neg['bin_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "084f6f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    binary_data, binary_target, test_size=0.3)\n",
    "\n",
    "# Construct Pipeline object\n",
    "txt_clf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('clf', MultinomialNB())\n",
    "    ]\n",
    ").fit(docs_train,y_train)\n",
    "\n",
    "# Predict from Pipeline\n",
    "y_pred_binary = txt_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82b13660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text example:\n",
      "I'm a crocoholic! I love the lined ones. My feet thank me. I wear them everywhere. But alas, I only have 6 pair. Need to get MORE,\n",
      "---\n",
      "Naive Bayes Prediction: positive\n",
      "Actual: positive\n"
     ]
    }
   ],
   "source": [
    "vals = {0:'negative',1:'positive'}\n",
    "pt = 123\n",
    "\n",
    "print(f\"Text example:\\n{docs_test[pt]}\")\n",
    "print('---')\n",
    "print(f\"Naive Bayes Prediction: {vals[y_pred_binary[pt]]}\")\n",
    "print(f\"Actual: {vals[y_test[pt]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "25307064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.91      0.93       511\n",
      "         1.0       0.93      0.95      0.94       604\n",
      "\n",
      "    accuracy                           0.93      1115\n",
      "   macro avg       0.93      0.93      0.93      1115\n",
      "weighted avg       0.93      0.93      0.93      1115\n",
      "\n",
      "Confusion Matrix:\n",
      "[[466  45]\n",
      " [ 30 574]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of our model\n",
    "print(f\"Naive Bayes Model:\\n{metrics.classification_report(y_test, y_pred_binary)}\")\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_binary)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44a70830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary Naive Bayes Predictions:\n",
      "The sentence \"I like this product.\" is 1.0\n",
      "The sentence \"I dislike this product.\" is 0.0\n",
      "The sentence \"The product is amazing.\" is 1.0\n",
      "The sentence \"The product is terrible.\" is 0.0\n",
      "The sentence \"The world is good.\" is 1.0\n",
      "The sentence \"The world is bad.\" is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use txt_clf to predict binary sentiment of new sentences\n",
    "sentences = [\n",
    "    # Subjective 1st Person\n",
    "    \"I like this product.\",\n",
    "    \"I dislike this product.\",\n",
    "    # Subjective 3rd Person\n",
    "    \"The product is amazing.\",\n",
    "    \"The product is terrible.\",\n",
    "    # General 3rd person\n",
    "    \"The world is good.\",\n",
    "    \"The world is bad.\"\n",
    "]\n",
    "\n",
    "new_pred = txt_clf.predict(sentences)\n",
    "print(\"Binary Naive Bayes Predictions:\")\n",
    "evaluate_predictions(new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffce79",
   "metadata": {},
   "source": [
    "# Binned Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f133035",
   "metadata": {},
   "source": [
    "In this model, we increase the complexity and include the full dataset. In preprocessing, we bin the data into 3 groups; group 1 contains the 1- & 2-star text examples, group 2 contains the 3-star text examples, and group 3 contains the 4- & 5-star text examples. In this way, we give our model an idea how to capture text polarity without increasing the computational complexity tremendously. Once again, we fit the pre-processed data into our text classifier and see a diminished level of accuracy, but still a significantly high accuracy in testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "712afaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Preprocess\n",
    "\n",
    "# Copy over master df\n",
    "binned_df = df.copy()\n",
    "# Initialize empty column\n",
    "sent = []\n",
    "\n",
    "# Loop through copy of master\n",
    "for i in binned_df['stars']:\n",
    "    # Apply bin label to empty column based on value of 'stars'\n",
    "    # Greater than 3 stars = 1\n",
    "    if i > 3:\n",
    "        sent.append(1)\n",
    "    # 3 stars = 0\n",
    "    elif i == 3:\n",
    "        sent.append(0)\n",
    "    # Less than 3 stars = -1\n",
    "    else: \n",
    "        sent.append(-1)\n",
    "# Append column to binned_df\n",
    "binned_df['sent'] = sent\n",
    "    \n",
    "# Separate binned_df into data & target\n",
    "binned_data = np.array(binned_df['text'])\n",
    "binned_target = np.array(binned_df['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5987559f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    binned_data, binned_target, test_size=0.4)\n",
    "\n",
    "# Construct Pipeline object\n",
    "txt_clf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('clf', SGDClassifier(loss='squared_hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          tol=None))\n",
    "    ]\n",
    ").fit(docs_train,y_train)\n",
    "\n",
    "# Predict from Pipeline\n",
    "y_pred_binned = txt_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f40f5e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.70      0.86      0.77      1107\n",
      "           0       0.54      0.15      0.23       634\n",
      "           1       0.78      0.90      0.83      1377\n",
      "\n",
      "    accuracy                           0.73      3118\n",
      "   macro avg       0.67      0.64      0.61      3118\n",
      "weighted avg       0.70      0.73      0.69      3118\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 955   46  106]\n",
      " [ 300   94  240]\n",
      " [ 110   34 1233]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of our model\n",
    "print(f\"SGD Model:\\n{metrics.classification_report(y_test, y_pred_binned)}\")\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_binned)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa9e7896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polar SGD Classifications\n",
      "The sentence \"I like this product.\" is 1\n",
      "The sentence \"I dislike this product.\" is -1\n",
      "The sentence \"The product is amazing.\" is 1\n",
      "The sentence \"The product is terrible.\" is -1\n",
      "The sentence \"The world is good.\" is 1\n",
      "The sentence \"The world is bad.\" is -1\n"
     ]
    }
   ],
   "source": [
    "# Use txt_clf to predict binned sentiment of new sentences\n",
    "sentences = [\n",
    "    # Subjective 1st Person\n",
    "    \"I like this product.\",\n",
    "    \"I dislike this product.\",\n",
    "    # Subjective 3rd Person\n",
    "    \"The product is amazing.\",\n",
    "    \"The product is terrible.\",\n",
    "    # General 3rd person\n",
    "    \"The world is good.\",\n",
    "    \"The world is bad.\"\n",
    "]\n",
    "\n",
    "new_pred = txt_clf.predict(sentences)\n",
    "print(\"Polar SGD Classifications\")\n",
    "evaluate_predictions(new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b7506f",
   "metadata": {},
   "source": [
    "# Star Count Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b725786a",
   "metadata": {},
   "source": [
    "Seeing the trend from the previous two models, we can intuitively expect this model to be the least accurate and most computationally complex. We find a ~55% testing accuracy from our star prediction model; however, when we return to the original sentences, we find the model surprisingly accurate to what one would rate our original reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60707435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Preprocess\n",
    "\n",
    "# Separate df into data & target\n",
    "cat_data = np.array(df['text'])\n",
    "cat_target = np.array(df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0cb26a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    cat_data, cat_target, test_size=0.4)\n",
    "\n",
    "# Construct Pipeline object\n",
    "txt_clf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('clf', SGDClassifier(loss='squared_hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          tol=None))\n",
    "    ]\n",
    ").fit(docs_train,y_train)\n",
    "\n",
    "# Predict from Pipeline\n",
    "y_pred_cat = txt_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "679c4547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regression Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.57      0.80      0.66       719\n",
      "           2       0.34      0.10      0.16       446\n",
      "           3       0.41      0.37      0.39       635\n",
      "           4       0.46      0.33      0.38       547\n",
      "           5       0.65      0.85      0.74       771\n",
      "\n",
      "    accuracy                           0.54      3118\n",
      "   macro avg       0.49      0.49      0.47      3118\n",
      "weighted avg       0.50      0.54      0.50      3118\n",
      "\n",
      "Confusion Matrix:\n",
      "[[575  23  68  21  32]\n",
      " [205  45 120  34  42]\n",
      " [165  60 237  92  81]\n",
      " [ 37   5 129 181 195]\n",
      " [ 29   1  19  68 654]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of our model\n",
    "print(f\"Regression Model:\\n{metrics.classification_report(y_test, y_pred_cat)}\")\n",
    "cm = metrics.confusion_matrix(y_test, y_pred_cat)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0923eb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Count Regression Predictions:\n",
      "The sentence \"I like this product.\" is 2\n",
      "The sentence \"I dislike this product.\" is 1\n",
      "The sentence \"The product is amazing.\" is 5\n",
      "The sentence \"The product is terrible.\" is 2\n",
      "The sentence \"The world is good.\" is 3\n",
      "The sentence \"The world is bad.\" is 2\n"
     ]
    }
   ],
   "source": [
    "# Use txt_clf to predict categorical sentiment of new sentences\n",
    "sentences = [\n",
    "    # Subjective 1st Person\n",
    "    \"I like this product.\",\n",
    "    \"I dislike this product.\",\n",
    "    # Subjective 3rd Person\n",
    "    \"The product is amazing.\",\n",
    "    \"The product is terrible.\",\n",
    "    # General 3rd person\n",
    "    \"The world is good.\",\n",
    "    \"The world is bad.\"\n",
    "]\n",
    "\n",
    "new_pred = txt_clf.predict(sentences)\n",
    "print(\"Star Count Regression Predictions:\")\n",
    "evaluate_predictions(new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e2b485",
   "metadata": {},
   "source": [
    "## How successful were we at achieving our goal?"
   ]
  },
  {
   "attachments": {
    "cm.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "781a2c8f",
   "metadata": {},
   "source": [
    "Our original intent was to train a(n) NLP model to categorize sentiment in product reviews.\n",
    "\n",
    "If we take the predictive accuracy of the model to be the determining factor of the 'success' of our model, then we have a model that is in need of much further optimization. In reality, our model can definitely benefit from further optimization, but from our confusion matrix, we can tell that the model is still making strong predictions, predictions that humans may even make when guessing the amount of stars a particular review has recieved.\n",
    "\n",
    "Below is an annotated version of the confusion matrix for the star regressor model. Referencing our previous 2 models, we first binned sentiment as all of the 5-star and 1-star reviews. \n",
    "* Our model only misclassifies a 5 as a 1 25 times and another 31 times it misclassifies a 1 as a 5. \n",
    "* The misclassifications in yellow are also not optimal classifications, but fortunately we see very few of those as well. \n",
    "* The misclassifications in green and blue start to blur the lines. Neutral sentiment is a struggle for this particular method of classification because we are taking the term frequencies with respect to the entire corpus. The non-polarized examples have to be learned from sentiments without powerful tokens and we are limited by the length of our Walmart corpus in determining the non-polarized words. In other words, there are probably incorrect tokens denoting neutrality in our dataset because it is not large enough to train those out\n",
    "* The misclassifications in blue might as well be accurate as they represent predictions that are off by a single star, and this is the range with the most misclassifications\n",
    "\n",
    "Doesn't that sound pretty much like the ~95% accuracy we were finding using the same method for tokenization, vectorization and classification using the naive Bayes model?\n",
    "\n",
    "I would argue that our categorical model makes strong predictions in regressing the number of stars a review would recieve, even though the accuracy in testing is disheartening\n",
    "\n",
    "\n",
    "![cm.png](attachment:cm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fadc4a83",
   "metadata": {},
   "source": [
    "Moving forward in optimization of a general purpose review classifier, we would want to augment how we structure our preprocessed text data. In other words, we would want to create some dimension more valuable to the *context* of the words than the relative term frequencies across the entire training corpus. \n",
    "\n",
    "One popular example is utilizing word embeddings. Word embeddings are vectorized forms of the tokens with respect to certain dimensions. Deep neural networks are capable of finding the most optimable word embedding vectors by visualizing the entire vocabulary of the text data in an n-dimensional vector space. \n",
    "\n",
    "Keras has an awesome tool for creating word embeddings right within a Keras deep-learning architecture. This is the future direction for this project in training a deep neural network to classify the polarity of our Walmart reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5124e8ea",
   "metadata": {},
   "source": [
    "# Considering Model Design"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c882c3",
   "metadata": {},
   "source": [
    "The Sentiment Initensity Analyzer is a pretrained VADER NLP classifier and specifically tuned to sentiments expressed in social media.\n",
    "\n",
    "* Similar to the models we created before, this NLP classification tools utilizes words as tokens and vectorizes those words to give the tokens some value relative to their semantic orientation, either positive or negative. \n",
    "\n",
    "* Unlike the models we created before, this NLP classification tool is trained on a massive compiling of social media texts containing the same labeling system as we use for our Walmart product data. \n",
    "\n",
    "What's the difference? \n",
    "> Strictly numerically speaking, the pre-trained model should be capable of adjusting to more robustness in what words a given text example contains and make better predictions of the sentiment of *any* given text. The sheer quantity of text data that the SIA model has been trained on makes it a stronger option for general purpose text classification and a weaker option for niche text classification pruposes. Thus, we expect our own trained model to outperform the accuracy of the pre-trained model in this case.\n",
    "\n",
    "Now I'm more confused, how is the smaller model better?\n",
    "> So, when we trained our own model, we utilized a subset of our data to train and a smaller subset to test. This is a valid procedure for evaluating the direct predictive accuracy. However, now we also have a model that is biased in its understanding of natural language toward the way that our Walmart dataset it structured. In other words, the model becomes good at classifying Walmart reviews, whereas the SIA model is stronger at general purpose sentiment analyization because of the sheer amount of text data it has already been trained on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ff4a571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets import the pre-trained model API and save it in an object called sia\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2056ca9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"I like this product.\" is 0.3612\n",
      "The sentence \"I dislike this product.\" is -0.3818\n",
      "The sentence \"The product is amazing.\" is 0.5859\n",
      "The sentence \"The product is terrible.\" is -0.4767\n",
      "The sentence \"The world is good.\" is 0.4404\n",
      "The sentence \"The world is bad.\" is -0.5423\n"
     ]
    }
   ],
   "source": [
    "# Let's revisit the original sentences we tested our model on before\n",
    "sentences = [\n",
    "    # Subjective 1st Person\n",
    "    \"I like this product.\",\n",
    "    \"I dislike this product.\",\n",
    "    # Subjective 3rd Person\n",
    "    \"The product is amazing.\",\n",
    "    \"The product is terrible.\",\n",
    "    # General 3rd person\n",
    "    \"The world is good.\",\n",
    "    \"The world is bad.\"\n",
    "]\n",
    "\n",
    "# empty list to contain predictions\n",
    "predictions = []\n",
    "# loop through and collect 'compound' from each polarity_scores dict\n",
    "for sentence in sentences:\n",
    "    compounds = list(sia.polarity_scores(sentence).values())[3]\n",
    "    predictions.append(compounds)\n",
    "# Call method to evaluate sentences\n",
    "evaluate_predictions(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a4f6a",
   "metadata": {},
   "source": [
    "Important to note right off the rip, the classification for neutral by our pretrained SIA model occurs at a compound score no greater than 0.05 or lesser than -0.05. This is because if the SIA model scores a text example greater than 0.05 negative or positive, that value has far greater impact on the compound score than the remaining percent scored neutral. On the other hand, if a text example scores less than 0.05 for both positive or negative, the classification defaults to 0.0 neutral because no token was able to sway the polarity of the text example. So, sentiment is polarized and laid out on this range from -1.0 to 1.0. \n",
    "\n",
    "-> And this is by far the best classification of the sentiment expressed in our original sentences so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e7b8fe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's regenerate the binned sentiment data for our model\n",
    "\n",
    "# Train Test Split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    binned_data, binned_target, test_size=0.4)\n",
    "\n",
    "# Construct Pipeline object\n",
    "txt_clf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('clf', SGDClassifier(loss='squared_hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          tol=None))\n",
    "    ]\n",
    ").fit(docs_train,y_train)\n",
    "\n",
    "# Predict from Pipeline\n",
    "y_pred_binned = txt_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "306a3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, let's generate some scores for the Sentiment Intensity Analyzer and\n",
    "# label them in the same way as our binning\n",
    "\n",
    "# Initialize empty predictions list\n",
    "sia_pred = []\n",
    "# This specifies the range of values for classification of neutral (0) text sentiment\n",
    "bin_range = [-0.05, 0.05]\n",
    "\n",
    "# Loop through a range the length of our testing data\n",
    "for x in range(len(docs_test)):\n",
    "    # Collect the polarity score dictionary for the x-th text example\n",
    "    scores = sia.polarity_scores(docs_test[x])\n",
    "    # Isolate the compound score into its own variable\n",
    "    compound = list(scores.values())[3]\n",
    "    # If compound is greater than or equal to upper bound of neutral bin\n",
    "    if (compound >= bin_range[1]):\n",
    "        # Then classify as positive (1)\n",
    "        sia_pred.append(1)\n",
    "    # If compound is in the range of the bin \n",
    "    elif (compound < bin_range[1]) and (compound >= bin_range[0]):\n",
    "        # Then classify as neutral (0)\n",
    "        sia_pred.append(0)\n",
    "    # If compound is less than lower bound of neutral bin        \n",
    "    elif (compound < bin_range[0]) and (compound >= -1.0):\n",
    "        # Then classify as negative (-1)\n",
    "        sia_pred.append(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5f04cf10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy our trained model is 72.77%\n",
      "The accuracy the pre-trained model is 61.35%\n"
     ]
    }
   ],
   "source": [
    "# Let's construct a DataFrame object with the actual sentiment, our model's prediction\n",
    "# and the prediction of the pre-trained SIA model\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Actual Sentiment Class':y_test,\n",
    "    'Scikit Binned Trained':y_pred_binned,\n",
    "    'VADER SIA Pretrained':sia_pred\n",
    "})\n",
    "\n",
    "# Initialize unclean, dirty, bad counters\n",
    "s_c = 0\n",
    "v_c = 0\n",
    "# for loop through range of the length of our comparison_df\n",
    "for x in range(len(comparison_df)):\n",
    "    # save the values of the columns in our comparison_df into variables\n",
    "    actual = comparison_df.iloc[x,0]\n",
    "    scikit_correct = comparison_df.iloc[x,1]\n",
    "    vader_correct = comparison_df.iloc[x,2]\n",
    "\n",
    "    # Simple conditional; if they match, increase the counters\n",
    "    if actual == scikit_correct:\n",
    "        s_c += 1\n",
    "    if actual == vader_correct:\n",
    "        v_c += 1\n",
    "    \n",
    "    # Compute the success rate (mean) of our models\n",
    "    s_mean = (s_c / len(comparison_df))\n",
    "    v_mean = (v_c / len(comparison_df))\n",
    "\n",
    "\n",
    "print(f\"The accuracy our trained model is {(round(s_mean,4)*100)}%\")\n",
    "print(f\"The accuracy the pre-trained model is {(round(v_mean,4)*100)}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b802e91",
   "metadata": {},
   "source": [
    "## How can you apply the VADER model?\n",
    "\n",
    "We already established that the Sentment Intensity Analyzer using VADER metrics is a strong, computationally-small classifier of sentiment in any given text. Moving forward, it might be an interesting project to optimize our star regression model using VADER polarity scores. In other words, maybe we can use the magnitude of VADER's compound score to classify something as a 5-star review versus a 4-star review with better testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9e53c14c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 0:\n",
      "Lid is a disaster. Nice cup. Good choices in colors. Handle doesn't stay tight. The lid leaks bad. With or without straw a tip over will require a cleanup. Drinking without straw is also difficult due to where hole lines up with handle after screwing on lid. Ozark trail is usually my go to brand at Walmart,but this purchase will be returned.\n",
      "- Actual Sent:negative\n",
      "- Model Sent: negative\n",
      "- SIA prediction:{'neg': 0.17, 'neu': 0.75, 'pos': 0.081, 'compound': -0.743}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 1:\n",
      "Worn out in less than two months.\n",
      "- Actual Sent:negative\n",
      "- Model Sent: negative\n",
      "- SIA prediction:{'neg': 0.268, 'neu': 0.732, 'pos': 0.0, 'compound': -0.296}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 2:\n",
      "Can't go to the Internet from the TV\n",
      "- Actual Sent:positive\n",
      "- Model Sent: negative\n",
      "- SIA prediction:{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 3:\n",
      "Because the mattress comes in a box it is easy to manage when moving it around. For me that was getting it upstairs. This is my 2nd mattress in a box. The 1st one I got for my son 2 1/2 years ago and it is still a good mattress. My Tempurpedic was too hard and had to sell it after sleeping on it for 5 years. When my son left for college I tried his bed and my back stopped hurting so I was sold on getting myself a queen size. Love it.\n",
      "- Actual Sent:positive\n",
      "- Model Sent: positive\n",
      "- SIA prediction:{'neg': 0.063, 'neu': 0.832, 'pos': 0.105, 'compound': 0.7184}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 4:\n",
      "[This review was collected as part of a promotion.] Purchased a couple weeks ago for our bedroom. Picture quality is great, connects to my WiFi better than other tvs. Only complaint is I feel like the TV speakers could be better. A sound bar would be ideal.\n",
      "- Actual Sent:positive\n",
      "- Model Sent: positive\n",
      "- SIA prediction:{'neg': 0.04, 'neu': 0.673, 'pos': 0.287, 'compound': 0.9274}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 5:\n",
      "Bigger label on the package\n",
      "- Actual Sent:neutral\n",
      "- Model Sent: negative\n",
      "- SIA prediction:{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound': 0.0}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 6:\n",
      "tv started showing a double picture a month after we bought. not split screen actually same show one on top of the other\n",
      "- Actual Sent:neutral\n",
      "- Model Sent: negative\n",
      "- SIA prediction:{'neg': 0.0, 'neu': 0.917, 'pos': 0.083, 'compound': 0.2023}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 7:\n",
      "Delivery was better than a very disappointing TV. ! I was replacing a 10 year old 42”Vizio. The reliability leaned me to the Vizio.What a bad choice!Its not worth it to look at a bigger tv with the same screen.Honestly all the 4K UHD is not discernible.The border is still BIG\n",
      "- Actual Sent:negative\n",
      "- Model Sent: negative\n",
      "- SIA prediction:{'neg': 0.174, 'neu': 0.772, 'pos': 0.055, 'compound': -0.7463}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 8:\n",
      "Extremely disappointed! The screen started to scramble with lines going across after 1yr of use. Then went completely black by the 2nd year. Totally useless and surprised at how quickly this TV became inoperable! No more Vizios for me!\n",
      "- Actual Sent:negative\n",
      "- Model Sent: negative\n",
      "- SIA prediction:{'neg': 0.205, 'neu': 0.749, 'pos': 0.046, 'compound': -0.8125}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      " -- Text at index 9:\n",
      "i like my PS5 better, but alas i own one\n",
      "\n",
      "the walmart experience of buying and pickup without having to wait in understaffed queue lines was perfect. Wal Mart needs to stop being so cheap and pay people a dcent wage or give 10%off for those who use self checkout\n",
      "- Actual Sent:positive\n",
      "- Model Sent: positive\n",
      "- SIA prediction:{'neg': 0.13, 'neu': 0.717, 'pos': 0.153, 'compound': 0.3192}\n",
      "-=-=-=-=-=-=-=-=-=-=-=-=-=-\n",
      "-- Loading new example --\n"
     ]
    }
   ],
   "source": [
    "# Here's a useful tool for comparing our model with the SIA VADER model\n",
    "\n",
    "vals = {-1:'negative',0:'neutral',1:'positive'}\n",
    "\n",
    "for pt in range(0, 10):\n",
    "    print('-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "    print(f\" -- Text at index {pt}:\\n{docs_test[pt]}\")\n",
    "    print(f\"- Actual Sent:{vals[y_test[pt]]}\")\n",
    "    print(f\"- Model Sent: {vals[y_pred_binned[pt]]}\")\n",
    "    print(f\"- SIA prediction:{sia.polarity_scores(docs_test[pt])}\")\n",
    "    print('-=-=-=-=-=-=-=-=-=-=-=-=-=-')\n",
    "    print(\"-- Loading new example --\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
