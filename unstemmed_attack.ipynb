{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "pazYQbmUSCcv",
      "metadata": {
        "id": "pazYQbmUSCcv"
      },
      "source": [
        "# Setting up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "44126771",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "44126771",
        "outputId": "5167351f-3d3d-47a4-9d98-161a213616a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: textattack in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: bert-score>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.3.13)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack) (0.6.2)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (from textattack) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack) (3.13.1)\n",
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.10/dist-packages (from textattack) (2.7.1)\n",
            "Requirement already satisfied: lemminflect in /usr/local/lib/python3.10/dist-packages (from textattack) (0.2.3)\n",
            "Requirement already satisfied: lru-dict in /usr/local/lib/python3.10/dist-packages (from textattack) (1.3.0)\n",
            "Requirement already satisfied: datasets>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.17.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.11.4)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (4.38.1)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from textattack) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack) (4.66.2)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from textattack) (1.1)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from textattack) (0.5.13)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack) (10.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.7.1)\n",
            "Requirement already satisfied: pinyin>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.4.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack) (0.42.1)\n",
            "Requirement already satisfied: OpenHowNet in /usr/local/lib/python3.10/dist-packages (from textattack) (2.0)\n",
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.41)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (23.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2023.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.4.2)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.34.53)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.3.4)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.14)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (6.1.3)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.7.3)\n",
            "Requirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.3.2)\n",
            "Requirement already satisfied: janome>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.5.0)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.9.4)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (3.1)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.2)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.9.0)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.3.3)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.26.18)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.6.0)\n",
            "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (3.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (1.3.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->textattack) (0.6.2)\n",
            "Requirement already satisfied: anytree in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (2.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (67.7.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.53 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (1.34.53)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (0.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair->textattack) (0.1.99)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair->textattack) (6.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.3.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (3.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.27.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers>=4.30.0->textattack) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n"
          ]
        }
      ],
      "source": [
        "# Google Collab installation requirements\n",
        "!pip install datasets\n",
        "!pip install textattack\n",
        "!pip install scikit-learn\n",
        "!pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "612fe0dd",
      "metadata": {
        "id": "612fe0dd"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets\n",
        "import re\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import textattack\n",
        "from textattack.attack_recipes import TextFoolerJin2019\n",
        "from textattack import Attacker\n",
        "from abc import ABC, abstractmethod\n",
        "from pymongo import MongoClient\n",
        "#from passwords import password"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "252fb4ff",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "252fb4ff",
        "outputId": "541eca89-dfce-43cb-998a-f6a3ada91171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# the Natural Language Toolkit & tokenizer\n",
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "310977c2",
      "metadata": {
        "id": "310977c2"
      },
      "outputs": [],
      "source": [
        "# Connect to MongoDB\n",
        "\n",
        "# Initialize authentication & cursor variables\n",
        "password = 'WJwxIjCdmlGoCrN7'\n",
        "mongo_uri = f'mongodb+srv://kkosek:{password}@cluster0.lv4rmyj.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
        "db_name = 'walmart'\n",
        "collection_name = 'scraper'\n",
        "\n",
        "\n",
        "# Create a client\n",
        "client = MongoClient(mongo_uri)\n",
        "# Connect to the 'walmart' database\n",
        "db = client[db_name]\n",
        "# Open the 'scraper' collection\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Fetch all documents from the collection\n",
        "cursor = collection.find({})\n",
        "\n",
        "# Convert documents to a list of dictionaries\n",
        "documents = list(cursor)\n",
        "\n",
        "# Close the cursor and client\n",
        "cursor.close()\n",
        "client.close()\n",
        "\n",
        "# Convert the list of dicts to master DataFrame\n",
        "df = pd.DataFrame(documents)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "ts4W1oUeGvfe",
        "outputId": "781aec81-9b34-4f45-9ffc-1f0b4fed0c0b"
      },
      "id": "ts4W1oUeGvfe",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "0     My last Vizio tv was a    inch I think  It was...    1.0\n",
              "1     I purchased the     Vizio  K TV In part on the...    1.0\n",
              "2     This Vizio  K UHD is easy to setup may take so...    1.0\n",
              "3     Love the size  the clarity and the sound   ama...    1.0\n",
              "4     Great TV  picture is great  not a fan of the l...    1.0\n",
              "...                                                 ...    ...\n",
              "3710  Although I have quite a few pair that are not ...    0.0\n",
              "3711  Disappointed I wear a   baya lined now and thi...    0.0\n",
              "3712  These weren t the classic lined crocs I was lo...    0.0\n",
              "3713  Did not get my crocs  Could not track my crocs...    0.0\n",
              "3714  The item was irregular  one croc was wider the...    0.0\n",
              "\n",
              "[3715 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46b5c4ad-5a84-4e49-86ad-2ae948877f99\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My last Vizio tv was a    inch I think  It was...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I purchased the     Vizio  K TV In part on the...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This Vizio  K UHD is easy to setup may take so...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Love the size  the clarity and the sound   ama...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great TV  picture is great  not a fan of the l...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3710</th>\n",
              "      <td>Although I have quite a few pair that are not ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3711</th>\n",
              "      <td>Disappointed I wear a   baya lined now and thi...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3712</th>\n",
              "      <td>These weren t the classic lined crocs I was lo...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3713</th>\n",
              "      <td>Did not get my crocs  Could not track my crocs...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3714</th>\n",
              "      <td>The item was irregular  one croc was wider the...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3715 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46b5c4ad-5a84-4e49-86ad-2ae948877f99')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46b5c4ad-5a84-4e49-86ad-2ae948877f99 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46b5c4ad-5a84-4e49-86ad-2ae948877f99');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b61769f2-0b4b-4483-8f33-12c153056ae8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b61769f2-0b4b-4483-8f33-12c153056ae8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b61769f2-0b4b-4483-8f33-12c153056ae8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_8bd36212-9f85-4a00-a85a-93ebbeb1069b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_8bd36212-9f85-4a00-a85a-93ebbeb1069b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 3715,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3711,\n        \"samples\": [\n          \"The    ounce capacity of this reusable tumbler is fantastic for those who want to stay hydrated throughout the day without having to do  frequent refills  It features a double wall insulation which is great for keeping the Beverage at the required temperature for a long time  It means that I can enjoy my drinks at the temperature I prefer without having to rush to finish them  It can contain both hot and cold drinks  I really love the large handle which provides a firm grip and prevents the tumbler from slipping out of my hand  I also love that the straw can bend in multiple direction  While this tumbler has many impressive features  it may not be the best choice for everyone due to its large size  It can make it challenging to fit into sma   \",\n          \"Walmart services are excellent \",\n          \"their software is crap  youre stuck with apps they choose  cant get showtime  they spam you every day with annoying ads  they regularly brick your tv with  updates  so you have to reset and put your info back in  buy something else\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49921347871051786,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0TqfcfO5SHyT",
      "metadata": {
        "id": "0TqfcfO5SHyT"
      },
      "source": [
        "# Binary Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "836988f2",
      "metadata": {
        "id": "836988f2"
      },
      "outputs": [],
      "source": [
        "# Binary Sentiment Labelling\n",
        "\n",
        "# Create copy of master df\n",
        "binary_df = df.copy()\n",
        "# Create a copy of the 'stars' column where 'stars' is equal to 5\n",
        "five = binary_df.loc[ binary_df['stars'] == 5 ].copy()\n",
        "# Add a new column in the length of the DataFrame with all 1s to bin 5stars\n",
        "five['label'] = pd.Series( [x/x for x in range(1,len(five)+1)] , index=five.index )\n",
        "# Create a copy of the 'stars' column where 'stars' is equal to 1\n",
        "one = binary_df.loc[ binary_df['stars'] == 1 ].copy()\n",
        "# Add a new column in the length of the DataFrame with all 0s to bin 1stars\n",
        "one['label'] = pd.Series( [((x/x)-1) for x in range(1,len(one)+1)] , index=one.index )\n",
        "# Concat the binary sentiment df\n",
        "pos_neg = pd.concat( [five,one] )\n",
        "\n",
        "# Overwrite the master set to only contain the 'text' and 'label' data (& reset index)\n",
        "df = pos_neg[['text','label']].reset_index(drop=True)\n",
        "# Clear all non-alphabetic characters out of text file\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", str(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "frb65D3qSilR",
      "metadata": {
        "id": "frb65D3qSilR"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "1eb9a3cb",
      "metadata": {
        "id": "1eb9a3cb"
      },
      "outputs": [],
      "source": [
        "# Separate out into features (X) and target (y)\n",
        "df_X = df['text']\n",
        "df_y = df['label']\n",
        "\n",
        "# Perform a test split on the features & target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_X, df_y, test_size=0.15)\n",
        "\n",
        "# Restore the split data into DataFrame objects now organized by training & testing\n",
        "df_train = pd.DataFrame([X_train, y_train]).T\n",
        "df_test =pd.DataFrame([X_test, y_test]).T\n",
        "\n",
        "# Reset indices\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "# Relabel our columns\n",
        "df_train.columns = ['text', 'label']\n",
        "df_test.columns = ['text', 'label']\n",
        "\n",
        "# Retype the label to be int\n",
        "df_train['label'] = df_train['label'].astype(int)\n",
        "df_test['label'] = df_test['label'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Dr6dpuNwSmSM",
      "metadata": {
        "id": "Dr6dpuNwSmSM"
      },
      "source": [
        "# Fitting & Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "b2d614f4",
      "metadata": {
        "id": "b2d614f4"
      },
      "outputs": [],
      "source": [
        "# TF-IDF Vectorization of text examples\n",
        "\n",
        "# Initialize Vectorizer object\n",
        "Tfidf = TfidfVectorizer( ngram_range=(1, 3), max_features=100 )\n",
        "\n",
        "# Fit the vectorizer with the text data\n",
        "unstemmed_tfidf_vect_fit = Tfidf.fit(df_train['text'])\n",
        "\n",
        "# Using the text data, vectorize the training 'words' with respect to their own frequency\n",
        "# throughout the training corpus\n",
        "Tfidf_training = unstemmed_tfidf_vect_fit.transform(df_train['text'])\n",
        "# Convert those vectors into a DataFrame object\n",
        "df_train_tfidf_unstem = pd.DataFrame( Tfidf_training.toarray() )\n",
        "\n",
        "# Vectorize the testing 'words' with respect to their own frequency\n",
        "# throughout the training corpus\n",
        "Tfidf_testing = unstemmed_tfidf_vect_fit.transform(df_test['text'])\n",
        "# Convert those vectors into a DataFrame object\n",
        "df_test_tfidf_unstem = pd.DataFrame( Tfidf_testing.toarray() )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FJGYrTYFTTr_",
      "metadata": {
        "id": "FJGYrTYFTTr_"
      },
      "source": [
        "# Classifier & Testing Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "825db01a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "825db01a",
        "outputId": "c4b5396d-c962-404a-c280-4cb3c77ebe12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83       276\n",
            "           1       0.84      0.83      0.83       282\n",
            "\n",
            "    accuracy                           0.83       558\n",
            "   macro avg       0.83      0.83      0.83       558\n",
            "weighted avg       0.83      0.83      0.83       558\n",
            "\n",
            "Confusion Matrix:\n",
            "[[230  46]\n",
            " [ 48 234]]\n"
          ]
        }
      ],
      "source": [
        "# Define our classifier model\n",
        "log_reg = LogisticRegression(C=30, max_iter=200)\n",
        "# Fit that model on the stemmed & tokenized text examples with their recorded label (pos or neg)\n",
        "log_reg = log_reg.fit(df_train_tfidf_unstem, df_train[\"label\"])\n",
        "# Use fitted classifier to predict the label from the testing stems\n",
        "y_pred = log_reg.predict(df_test_tfidf_unstem)\n",
        "\n",
        "print(classification_report(df_test[\"label\"], y_pred))\n",
        "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eCsID534RLMb",
      "metadata": {
        "id": "eCsID534RLMb"
      },
      "source": [
        "# Class Restructuring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "5bfcb930",
      "metadata": {
        "id": "5bfcb930"
      },
      "outputs": [],
      "source": [
        "# This cell bypasses a bug encountered with the source code of the API. The method '.get_feature_names()' was\n",
        "# deprecated to '.get_feature_names_out()' in scikit >= 1.0.0, so the API encounters the error during normal functioning.\n",
        "# (I don't know enough about subclassing to do it with less code than hardwiring it in a jupyter cell..)\n",
        "\n",
        "class ModelWrapper(ABC):\n",
        "    \"\"\"A model wrapper queries a model with a list of text inputs.\n",
        "\n",
        "    Classification-based models return a list of lists, where each sublist\n",
        "    represents the model's scores for a given input.\n",
        "\n",
        "    Text-to-text models return a list of strings, where each string is the\n",
        "    output – like a translation or summarization – for a given input.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, text_input_list, **kwargs):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_grad(self, text_input):\n",
        "        \"\"\"Get gradient of loss with respect to input tokens.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _tokenize(self, inputs):\n",
        "        \"\"\"Helper method for `tokenize`\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def tokenize(self, inputs, strip_prefix=False):\n",
        "        \"\"\"Helper method that tokenizes input strings\n",
        "        Args:\n",
        "            inputs (list[str]): list of input strings\n",
        "            strip_prefix (bool): If `True`, we strip auxiliary characters added to tokens as prefixes (e.g. \"##\" for BERT, \"Ġ\" for RoBERTa)\n",
        "        Returns:\n",
        "            tokens (list[list[str]]): List of list of tokens as strings\n",
        "        \"\"\"\n",
        "        tokens = self._tokenize(inputs)\n",
        "        if strip_prefix:\n",
        "            # `aux_chars` are known auxiliary characters that are added to tokens\n",
        "            strip_chars = [\"##\", \"Ġ\", \"__\"]\n",
        "            # TODO: Find a better way to identify prefixes. These depend on the model, so cannot be resolved in ModelWrapper.\n",
        "\n",
        "            def strip(s, chars):\n",
        "                for c in chars:\n",
        "                    s = s.replace(c, \"\")\n",
        "                return s\n",
        "\n",
        "            tokens = [[strip(t, strip_chars) for t in x] for x in tokens]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "class SklearnModelWrapper(ModelWrapper):\n",
        "    \"\"\"Loads a scikit-learn model and tokenizer (tokenizer implements\n",
        "    `transform` and model implements `predict_proba`).\n",
        "\n",
        "    May need to be extended and modified for different types of\n",
        "    tokenizers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, text_input_list, batch_size=None):\n",
        "        encoded_text_matrix = self.tokenizer.transform(text_input_list).toarray()\n",
        "        tokenized_text_df = pd.DataFrame(\n",
        "            encoded_text_matrix)\n",
        "        return self.model.predict_proba(tokenized_text_df)\n",
        "\n",
        "    def get_grad(self, text_input):\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "RaD_icpIRP2z",
      "metadata": {
        "id": "RaD_icpIRP2z"
      },
      "source": [
        "# Launching our attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "f67d150e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f67d150e",
        "outputId": "4070a422-6671-4518-db5b-e324466f5022"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Unknown if model of class <class 'sklearn.linear_model._logistic.LogisticRegression'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:  10%|█         | 1/10 [00:00<00:00, 146.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 1 ---------------------------------------------\n",
            "[[1 (76%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "After one night sleeping on new bed my daughter s eyes  were almost swollen shut  day   her face red and swollen  day    and she is still crying in misery  What is in this mattress    I need a refund ASAP   \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 1 / 0 / 1 / 2:  20%|██        | 2/10 [00:06<00:27,  3.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 2 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (82%)]]\n",
            "\n",
            "[[Easy]] to order     pick up  Works [[great]] \n",
            "\n",
            "[[Convenience]] to order     pick up  Works [[admirable]] \n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 3 / 0 / 3 / 6:  60%|██████    | 6/10 [00:07<00:04,  1.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 3 ---------------------------------------------\n",
            "[[1 (94%)]] --> [[0 (61%)]]\n",
            "\n",
            "I [[love]] them  I [[love]] that I can just slip them on and have my feet be warm  They are so comfortable  I am going to look at another color for a variety  I m not the type of person who goes for pointed heels or tight binding shoes that hurt your feet  I love comfort and a shoe that can also be warn with just about anything  When I take them off I feel like I m still wearing comfort \n",
            "\n",
            "I [[adore]] them  I [[loves]] that I can just slip them on and have my feet be warm  They are so comfortable  I am going to look at another color for a variety  I m not the type of person who goes for pointed heels or tight binding shoes that hurt your feet  I love comfort and a shoe that can also be warn with just about anything  When I take them off I feel like I m still wearing comfort \n",
            "\n",
            "\n",
            "--------------------------------------------- Result 4 ---------------------------------------------\n",
            "[[1 (51%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "My daughter complained everyday that her skin itches every night\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 5 ---------------------------------------------\n",
            "[[0 (78%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "I don t know for sure if this is a tv my son will like yet since it is a Christmas gift  He will not receive it till then\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 6 ---------------------------------------------\n",
            "[[1 (80%)]] --> [[0 (73%)]]\n",
            "\n",
            "It s very [[easy]] to sign in on the tv   I like it s it s very nice   Nice screen I purchase another one\n",
            "\n",
            "It s very [[simple]] to sign in on the tv   I like it s it s very nice   Nice screen I purchase another one\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 3 / 2 / 3 / 8:  80%|████████  | 8/10 [00:07<00:01,  1.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 7 ---------------------------------------------\n",
            "[[0 (74%)]] --> [[[FAILED]]]\n",
            "\n",
            "It came broken in this corner  I m going to return it \n",
            "\n",
            "\n",
            "--------------------------------------------- Result 8 ---------------------------------------------\n",
            "[[0 (96%)]] --> [[[FAILED]]]\n",
            "\n",
            "Handle broke after a few months of use\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 5 / 2 / 3 / 10: 100%|██████████| 10/10 [00:08<00:00,  1.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 9 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[0 (54%)]]\n",
            "\n",
            "[[I]] Bought this for my brother and he was [[very]] pleased  [[I]] was able to ship it to his address  I [[love]] that  [[Easy]] transaction\n",
            "\n",
            "[[me]] Bought this for my brother and he was [[absolutely]] pleased  [[me]] was able to ship it to his address  I [[adore]] that  [[Comfortably]] transaction\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 10 ---------------------------------------------\n",
            "[[0 (88%)]] --> [[1 (52%)]]\n",
            "\n",
            "The [[screen]] was shattered when we [[bought]] it so we returned it   Usually Visio brand is our favorite \n",
            "\n",
            "The [[dropper]] was shattered when we [[purchase]] it so we returned it   Usually Visio brand is our favorite \n",
            "\n",
            "\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 5      |\n",
            "| Number of failed attacks:     | 2      |\n",
            "| Number of skipped attacks:    | 3      |\n",
            "| Original accuracy:            | 70.0%  |\n",
            "| Accuracy under attack:        | 20.0%  |\n",
            "| Attack success rate:          | 71.43% |\n",
            "| Average perturbed word %:     | 13.26% |\n",
            "| Average num. words per input: | 25.3   |\n",
            "| Avg num queries:              | 110.86 |\n",
            "+-------------------------------+--------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7d42c8cfd030>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7d42b18b8610>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7d42b1af7df0>,\n",
              " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7d42b1af6fb0>,\n",
              " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7d42b1af7220>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7d42b1b274f0>,\n",
              " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7d42b2e2c640>,\n",
              " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7d42b1af6680>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7d42c8cfc520>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7d42b3487ee0>]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Define a wrapper object to function similarly to a pipeline and hold our fitted classifier model\n",
        "# with our fitted vectorizor. The wrapper is engineered to function within the textattack architecture\n",
        "model_wrapper = SklearnModelWrapper(log_reg, unstemmed_tfidf_vect_fit)\n",
        "\n",
        "# The textattack architecture functions on textattack.datasets.Dataset objects\n",
        "# The convertor accepts a list of tuples containing inputs and output examples\n",
        "# For instance, (\"I like this product\", 1) represents a tuple containing an input and output\n",
        "# Thus, we create a list comprehension to compile the df['text'] & df['label'] into this format\n",
        "data = [(df_train['text'][x], int(df_train['label'][x])) for x in range(0,(len(df_train)))]\\\n",
        "# Then we call the textattack converter to assemble our data into the architecture\n",
        "dataset = textattack.datasets.Dataset(data)\n",
        "\n",
        "# The attack recipe in this attack is based on TextFooler, an adversarial attacker on NLP datasets that functions\n",
        "# by trying out iterations of tokens that can be modified slightly to cause the model to misclassify the sentiment\n",
        "# This attacker is pretrained and loaded into textattack libraries, so we can call it and build the adversarial\n",
        "# model based on our NLP model\n",
        "attack = TextFoolerJin2019.build(model_wrapper)\n",
        "# We can specifically add more arguments to the Attacker class, but the pretrained model is optimal as is\n",
        "attacker = Attacker(attack, dataset)\n",
        "# Call .attack_dataset() to create .attack instances across the whole dataset\n",
        "attacker.attack_dataset()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "frb65D3qSilR",
        "FJGYrTYFTTr_"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bootcampDev",
      "language": "python",
      "name": "bootcampdev"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}