{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Yf8K8Y2IRy9o",
      "metadata": {
        "id": "Yf8K8Y2IRy9o"
      },
      "source": [
        "# Setting up environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "8d166469",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8d166469",
        "outputId": "9e07ea91-6413-4d35-cd41-db5cfb811100"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.4->datasets) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: textattack in /usr/local/lib/python3.10/dist-packages (0.3.9)\n",
            "Requirement already satisfied: bert-score>=0.3.5 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.3.13)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from textattack) (0.6.2)\n",
            "Requirement already satisfied: flair in /usr/local/lib/python3.10/dist-packages (from textattack) (0.13.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from textattack) (3.13.1)\n",
            "Requirement already satisfied: language-tool-python in /usr/local/lib/python3.10/dist-packages (from textattack) (2.7.1)\n",
            "Requirement already satisfied: lemminflect in /usr/local/lib/python3.10/dist-packages (from textattack) (0.2.3)\n",
            "Requirement already satisfied: lru-dict in /usr/local/lib/python3.10/dist-packages (from textattack) (1.3.0)\n",
            "Requirement already satisfied: datasets>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.18.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from textattack) (3.8.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.25.2)\n",
            "Requirement already satisfied: pandas>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.11.4)\n",
            "Requirement already satisfied: torch!=1.8,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (2.1.0+cu121)\n",
            "Requirement already satisfied: transformers>=4.30.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (4.38.1)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from textattack) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from textattack) (4.66.2)\n",
            "Requirement already satisfied: word2number in /usr/local/lib/python3.10/dist-packages (from textattack) (1.1)\n",
            "Requirement already satisfied: num2words in /usr/local/lib/python3.10/dist-packages (from textattack) (0.5.13)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from textattack) (10.1.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from textattack) (1.7.1)\n",
            "Requirement already satisfied: pinyin>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.4.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from textattack) (0.42.1)\n",
            "Requirement already satisfied: OpenHowNet in /usr/local/lib/python3.10/dist-packages (from textattack) (2.0)\n",
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.10/dist-packages (from textattack) (0.41)\n",
            "Requirement already satisfied: click<8.1.0 in /usr/local/lib/python3.10/dist-packages (from textattack) (8.0.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (3.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from bert-score>=0.3.5->textattack) (23.2)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.3.8)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.2.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (0.20.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.4.0->textattack) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.1->textattack) (2023.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (3.1.3)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.8,>=1.7.0->textattack) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.4.2)\n",
            "Requirement already satisfied: boto3>=1.20.27 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.34.54)\n",
            "Requirement already satisfied: bpemb>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.3.4)\n",
            "Requirement already satisfied: conllu>=4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.5.3)\n",
            "Requirement already satisfied: deprecated>=1.2.13 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.14)\n",
            "Requirement already satisfied: ftfy>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (6.1.3)\n",
            "Requirement already satisfied: gdown>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.7.3)\n",
            "Requirement already satisfied: gensim>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.3.2)\n",
            "Requirement already satisfied: janome>=0.4.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.5.0)\n",
            "Requirement already satisfied: langdetect>=1.0.9 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.0.9)\n",
            "Requirement already satisfied: lxml>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (4.9.4)\n",
            "Requirement already satisfied: mpld3>=0.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.5.10)\n",
            "Requirement already satisfied: pptree>=3.1 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (3.1)\n",
            "Requirement already satisfied: pytorch-revgrad>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.2.2)\n",
            "Requirement already satisfied: segtok>=1.5.11 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.5.11)\n",
            "Requirement already satisfied: sqlitedict>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (2.1.0)\n",
            "Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.9.0)\n",
            "Requirement already satisfied: transformer-smaller-training-vocab>=0.2.3 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.3.3)\n",
            "Requirement already satisfied: urllib3<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (1.26.18)\n",
            "Requirement already satisfied: wikipedia-api>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (0.6.0)\n",
            "Requirement already satisfied: semver<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from flair->textattack) (3.0.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->textattack) (1.3.2)\n",
            "Requirement already satisfied: docopt>=0.6.2 in /usr/local/lib/python3.10/dist-packages (from num2words->textattack) (0.6.2)\n",
            "Requirement already satisfied: anytree in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (2.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from OpenHowNet->textattack) (67.7.2)\n",
            "Requirement already satisfied: botocore<1.35.0,>=1.34.54 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (1.34.54)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3>=1.20.27->flair->textattack) (0.10.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb>=0.3.2->flair->textattack) (0.1.99)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.13->flair->textattack) (1.14.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.4.0->textattack) (4.0.3)\n",
            "Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy>=6.1.0->flair->textattack) (0.2.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (1.16.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown>=4.4.0->flair->textattack) (4.12.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim>=4.2.0->flair->textattack) (6.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->bert-score>=0.3.5->textattack) (3.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bert-score>=0.3.5->textattack) (2024.2.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.2->flair->textattack) (3.3.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (3.20.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.8,>=1.7.0->textattack) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.8,>=1.7.0->textattack) (1.3.0)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.30.0->textattack) (0.27.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown>=4.4.0->flair->textattack) (2.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers>=4.30.0->textattack) (5.9.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.10/dist-packages (4.6.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from pymongo) (2.6.1)\n"
          ]
        }
      ],
      "source": [
        "# Google Collab installation requirements\n",
        "!pip install datasets\n",
        "!pip install textattack\n",
        "!pip install scikit-learn\n",
        "!pip install pymongo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "8d2f90fa",
      "metadata": {
        "id": "8d2f90fa"
      },
      "outputs": [],
      "source": [
        "# Dependencies\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datasets\n",
        "import re\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import PorterStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "import textattack\n",
        "from textattack.attack_recipes import TextFoolerJin2019\n",
        "from textattack import Attacker\n",
        "from abc import ABC, abstractmethod\n",
        "from pymongo import MongoClient\n",
        "#from passwords import password\n",
        "password = 'WJwxIjCdmlGoCrN7'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "564b2c3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "564b2c3d",
        "outputId": "72ec95ad-271f-4ae4-acba-6350c0522dd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# the Natural Language Toolkit & tokenizer\n",
        "import nltk\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "0d89d668",
      "metadata": {
        "id": "0d89d668"
      },
      "outputs": [],
      "source": [
        "# Connect to MongoDB\n",
        "\n",
        "# Initialize authentication & cursor variables\n",
        "mongo_uri = f'mongodb+srv://kkosek:{password}@cluster0.lv4rmyj.mongodb.net/?retryWrites=true&w=majority&appName=Cluster0'\n",
        "db_name = 'walmart'\n",
        "collection_name = 'scraper'\n",
        "\n",
        "# Create a client\n",
        "client = MongoClient(mongo_uri)\n",
        "# Connect to the 'walmart' database\n",
        "db = client[db_name]\n",
        "# Open the 'scraper' collection\n",
        "collection = db[collection_name]\n",
        "\n",
        "# Fetch all documents from the collection\n",
        "cursor = collection.find({})\n",
        "\n",
        "# Convert documents to a list of dictionaries\n",
        "documents = list(cursor)\n",
        "\n",
        "# Close the cursor and client\n",
        "cursor.close()\n",
        "client.close()\n",
        "\n",
        "# Convert the list of dicts to master DataFrame\n",
        "df = pd.DataFrame(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "FWwbIxymRnfk",
      "metadata": {
        "id": "FWwbIxymRnfk"
      },
      "source": [
        "# Binary Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "0610ec01",
      "metadata": {
        "id": "0610ec01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "692b1b50-aadf-4d0f-fdd0-1f17da655b90"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'stars'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'stars'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-315c5beff763>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbinary_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Create a copy of the 'stars' column where 'stars' is equal to 5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mfive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0mbinary_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'stars'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m5\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# Add a new column in the length of the DataFrame with all 1s to bin 5stars\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfive\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mx\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'stars'"
          ]
        }
      ],
      "source": [
        "# Binary Sentiment Labelling\n",
        "\n",
        "# Create copy of master df\n",
        "binary_df = df.copy()\n",
        "# Create a copy of the 'stars' column where 'stars' is equal to 5\n",
        "five = binary_df.loc[ binary_df['stars'] == 5 ].copy()\n",
        "# Add a new column in the length of the DataFrame with all 1s to bin 5stars\n",
        "five['label'] = pd.Series( [x/x for x in range(1,len(five)+1)] , index=five.index )\n",
        "# Create a copy of the 'stars' column where 'stars' is equal to 1\n",
        "one = binary_df.loc[ binary_df['stars'] == 1 ].copy()\n",
        "# Add a new column in the length of the DataFrame with all 0s to bin 1stars\n",
        "one['label'] = pd.Series( [((x/x)-1) for x in range(1,len(one)+1)] , index=one.index )\n",
        "# Concat the binary sentiment df\n",
        "pos_neg = pd.concat( [five,one] )\n",
        "\n",
        "# Overwrite the master set to only contain the 'text' and 'label' data (& reset index)\n",
        "df = pos_neg[['text','label']].reset_index(drop=True)\n",
        "# Clear all non-alphabetic characters out of text file\n",
        "df[\"text\"] = df[\"text\"].apply(lambda x: re.sub(\"[^a-zA-Z]\", \" \", str(x)))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1ufAhvW6Kz1y",
      "metadata": {
        "id": "1ufAhvW6Kz1y"
      },
      "source": [
        "# *Stemming Algorithm*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "f74d4a7c",
      "metadata": {
        "id": "f74d4a7c"
      },
      "outputs": [],
      "source": [
        "# Tokenize Reviews in training\n",
        "\n",
        "# Start by copying the master into df_tokenized\n",
        "df_tokenized = df.copy()\n",
        "# Loop through the column and tokenize the text\n",
        "tokened_reviews = [word_tokenize(rev) for rev in df_tokenized[\"text\"]]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "okg3Kiw5BuZu",
      "metadata": {
        "id": "okg3Kiw5BuZu"
      },
      "source": [
        "The Porter stemming algorithm classifies every character in a given token as either a consonant (\"c\") or vowel (\"v\"), grouping subsequent consonants as \"C\" and subsequent vowels as \"V.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "tweamnp3Bqcu",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "tweamnp3Bqcu",
        "outputId": "0a4b02ca-eef9-4499-a14d-a30e5e0d1813"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  \\\n",
              "0     My last Vizio tv was a    inch I think  It was...   \n",
              "1     I purchased the     Vizio  K TV In part on the...   \n",
              "2     This Vizio  K UHD is easy to setup may take so...   \n",
              "3     Love the size  the clarity and the sound   ama...   \n",
              "4     Great TV  picture is great  not a fan of the l...   \n",
              "...                                                 ...   \n",
              "3710  Although I have quite a few pair that are not ...   \n",
              "3711  Disappointed I wear a   baya lined now and thi...   \n",
              "3712  These weren t the classic lined crocs I was lo...   \n",
              "3713  Did not get my crocs  Could not track my crocs...   \n",
              "3714  The item was irregular  one croc was wider the...   \n",
              "\n",
              "                                                stemmed  label  \n",
              "0     my last vizio tv wa a inch i think it wa almos...    1.0  \n",
              "1     i purchas the vizio k tv in part on the streng...    1.0  \n",
              "2     thi vizio k uhd is easi to setup may take some...    1.0  \n",
              "3     love the size the clariti and the sound amaz m...    1.0  \n",
              "4     great tv pictur is great not a fan of the leg ...    1.0  \n",
              "...                                                 ...    ...  \n",
              "3710  although i have quit a few pair that are not l...    0.0  \n",
              "3711  disappoint i wear a baya line now and thi new ...    0.0  \n",
              "3712  these weren t the classic line croc i wa look ...    0.0  \n",
              "3713  did not get my croc could not track my croc em...    0.0  \n",
              "3714  the item wa irregular one croc wa wider then t...    0.0  \n",
              "\n",
              "[3715 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8ed514ba-dabe-43e8-9226-4466365d08fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>stemmed</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>My last Vizio tv was a    inch I think  It was...</td>\n",
              "      <td>my last vizio tv wa a inch i think it wa almos...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I purchased the     Vizio  K TV In part on the...</td>\n",
              "      <td>i purchas the vizio k tv in part on the streng...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This Vizio  K UHD is easy to setup may take so...</td>\n",
              "      <td>thi vizio k uhd is easi to setup may take some...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Love the size  the clarity and the sound   ama...</td>\n",
              "      <td>love the size the clariti and the sound amaz m...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Great TV  picture is great  not a fan of the l...</td>\n",
              "      <td>great tv pictur is great not a fan of the leg ...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3710</th>\n",
              "      <td>Although I have quite a few pair that are not ...</td>\n",
              "      <td>although i have quit a few pair that are not l...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3711</th>\n",
              "      <td>Disappointed I wear a   baya lined now and thi...</td>\n",
              "      <td>disappoint i wear a baya line now and thi new ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3712</th>\n",
              "      <td>These weren t the classic lined crocs I was lo...</td>\n",
              "      <td>these weren t the classic line croc i wa look ...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3713</th>\n",
              "      <td>Did not get my crocs  Could not track my crocs...</td>\n",
              "      <td>did not get my croc could not track my croc em...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3714</th>\n",
              "      <td>The item was irregular  one croc was wider the...</td>\n",
              "      <td>the item wa irregular one croc wa wider then t...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3715 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8ed514ba-dabe-43e8-9226-4466365d08fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8ed514ba-dabe-43e8-9226-4466365d08fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8ed514ba-dabe-43e8-9226-4466365d08fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ae251990-ef2d-4b68-88a8-6ce272e0560d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ae251990-ef2d-4b68-88a8-6ce272e0560d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ae251990-ef2d-4b68-88a8-6ce272e0560d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_29dbbf0f-9848-4550-9721-a6824498ee88\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_tokenized')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_29dbbf0f-9848-4550-9721-a6824498ee88 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_tokenized');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tokenized",
              "summary": "{\n  \"name\": \"df_tokenized\",\n  \"rows\": 3715,\n  \"fields\": [\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3711,\n        \"samples\": [\n          \"The    ounce capacity of this reusable tumbler is fantastic for those who want to stay hydrated throughout the day without having to do  frequent refills  It features a double wall insulation which is great for keeping the Beverage at the required temperature for a long time  It means that I can enjoy my drinks at the temperature I prefer without having to rush to finish them  It can contain both hot and cold drinks  I really love the large handle which provides a firm grip and prevents the tumbler from slipping out of my hand  I also love that the straw can bend in multiple direction  While this tumbler has many impressive features  it may not be the best choice for everyone due to its large size  It can make it challenging to fit into sma   \",\n          \"Walmart services are excellent \",\n          \"their software is crap  youre stuck with apps they choose  cant get showtime  they spam you every day with annoying ads  they regularly brick your tv with  updates  so you have to reset and put your info back in  buy something else\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"stemmed\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3704,\n        \"samples\": [\n          \"order the xbox twice through walmart for store pickup and they cancel on me twice wa tri to get it for anway i bought it elsewher for the same price\",\n          \"i wa overwhelm by the choic but knew i want a vizio sinc my current tv is a vizio but smaller plu thi wa on sale for under awesom pictur qualiti and sound is great but i ll definit be invest in a soundbar\",\n          \"when i open the box the tv wa bend on one side side\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"label\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.49921347871051786,\n        \"min\": 0.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0.0,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# Create word stems\n",
        "stemmed_tokens = []\n",
        "# Initialize a Stemming object\n",
        "porter = PorterStemmer()\n",
        "# Loop through the tokenized reviews and create stemmed_tokens\n",
        "for i in range(len(tokened_reviews)):\n",
        "    # Encode the characters\n",
        "    stems = [porter.stem(token) for token in tokened_reviews[i]]\n",
        "    # Join the encodings\n",
        "    stems = \" \".join(stems)\n",
        "    # append encodings back into words that the computer understands\n",
        "    stemmed_tokens.append(stems)\n",
        "# Insert this information into the df\n",
        "df_tokenized.insert(1, column=\"stemmed\", value=stemmed_tokens)\n",
        "df_tokenized"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aqz_pFWbKpTO",
      "metadata": {
        "id": "aqz_pFWbKpTO"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "5e69521e",
      "metadata": {
        "id": "5e69521e"
      },
      "outputs": [],
      "source": [
        "# Separate out into features (X) and target (y)\n",
        "df_tokenized_X = df_tokenized['stemmed']\n",
        "df_tokenized_y = df_tokenized['label']\n",
        "\n",
        "# Perform a test split on the features & target\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df_tokenized_X, df_tokenized_y, test_size=0.1)\n",
        "\n",
        "# Restore the split data into DataFrame objects now organized by training & testing\n",
        "df_train = pd.DataFrame([X_train, y_train]).T\n",
        "df_test =pd.DataFrame([X_test, y_test]).T\n",
        "\n",
        "# Reset indices\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_test = df_test.reset_index(drop=True)\n",
        "\n",
        "# Relabel our columns\n",
        "df_train.columns = ['stemmed', 'label']\n",
        "df_test.columns = ['stemmed', 'label']\n",
        "\n",
        "# Retype the label to be int\n",
        "df_train['label'] = df_train['label'].astype(int)\n",
        "df_test['label'] = df_test['label'].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JOpaJ8CkMGTs",
      "metadata": {
        "id": "JOpaJ8CkMGTs"
      },
      "source": [
        "# Fitting & Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "647594c2",
      "metadata": {
        "id": "647594c2"
      },
      "outputs": [],
      "source": [
        "# TF-IDF Vectorization of text examples\n",
        "\n",
        "# Initialize Vectorizer object\n",
        "Tfidf = TfidfVectorizer(\n",
        "    ngram_range=(1, 3), max_features=100\n",
        "    )\n",
        "# Fit the vectorizer with the tokenized & stemmed text data\n",
        "stemmed_tfidf_vect_fit = Tfidf.fit(df_train['stemmed'])\n",
        "\n",
        "# Using the fitted stemmed text data, vectorize the training stems with respect to their own frequency\n",
        "# throughout the training corpus\n",
        "Tfidf_training = stemmed_tfidf_vect_fit.transform(df_train['stemmed'])\n",
        "# Convert those vectors into a DataFrame object\n",
        "df_train_tfidf_stem = pd.DataFrame( Tfidf_training.toarray() )\n",
        "\n",
        "# Using the fitted stemmed text data, vectorize the testing stems with respect to their own frequency\n",
        "# throughout the training corpus\n",
        "Tfidf_testing = stemmed_tfidf_vect_fit.transform(df_test['stemmed'])\n",
        "# Convert those vectors into a DataFrame object\n",
        "df_test_tfidf_stem = pd.DataFrame( Tfidf_testing.toarray() )\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tKwBSmnPNfED",
      "metadata": {
        "id": "tKwBSmnPNfED"
      },
      "source": [
        "# Classifier & Testing Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "1591df9a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1591df9a",
        "outputId": "64341657-1f17-4257-8129-9ccf5c38ea14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.84      0.86       183\n",
            "           1       0.85      0.88      0.86       189\n",
            "\n",
            "    accuracy                           0.86       372\n",
            "   macro avg       0.86      0.86      0.86       372\n",
            "weighted avg       0.86      0.86      0.86       372\n",
            "\n",
            "Confusion Matrix:\n",
            "[[154  29]\n",
            " [ 23 166]]\n"
          ]
        }
      ],
      "source": [
        "# Define our classifier model\n",
        "log_reg = LogisticRegression(C=30, max_iter=200)\n",
        "# Fit that model on the stemmed & tokenized text examples with their recorded label (pos or neg)\n",
        "log_reg = log_reg.fit(df_train_tfidf_stem, df_train[\"label\"])\n",
        "# Use fitted classifier to predict the label from the testing stems\n",
        "y_pred = log_reg.predict(df_test_tfidf_stem)\n",
        "\n",
        "print(classification_report(df_test[\"label\"], y_pred))  # Evaluating prediction ability\n",
        "print(f\"Confusion Matrix:\\n{metrics.confusion_matrix(y_test, y_pred)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0CaHzmtFRaK3",
      "metadata": {
        "id": "0CaHzmtFRaK3"
      },
      "source": [
        "# Class Restructuring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "rbtjv9vx8XnL",
      "metadata": {
        "id": "rbtjv9vx8XnL"
      },
      "outputs": [],
      "source": [
        "# This cell bypasses a bug encountered with the source code of the API. The method '.get_feature_names()' was\n",
        "# deprecated to '.get_feature_names_out()' in scikit >= 1.0.0, so the API encounters the error during normal functioning.\n",
        "# (I don't know enough about subclassing to do it with less code than hardwiring it in a jupyter cell..)\n",
        "\n",
        "class ModelWrapper(ABC):\n",
        "    \"\"\"A model wrapper queries a model with a list of text inputs.\n",
        "\n",
        "    Classification-based models return a list of lists, where each sublist\n",
        "    represents the model's scores for a given input.\n",
        "\n",
        "    Text-to-text models return a list of strings, where each string is the\n",
        "    output – like a translation or summarization – for a given input.\n",
        "    \"\"\"\n",
        "\n",
        "    @abstractmethod\n",
        "    def __call__(self, text_input_list, **kwargs):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_grad(self, text_input):\n",
        "        \"\"\"Get gradient of loss with respect to input tokens.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def _tokenize(self, inputs):\n",
        "        \"\"\"Helper method for `tokenize`\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def tokenize(self, inputs, strip_prefix=False):\n",
        "        \"\"\"Helper method that tokenizes input strings\n",
        "        Args:\n",
        "            inputs (list[str]): list of input strings\n",
        "            strip_prefix (bool): If `True`, we strip auxiliary characters added to tokens as prefixes (e.g. \"##\" for BERT, \"Ġ\" for RoBERTa)\n",
        "        Returns:\n",
        "            tokens (list[list[str]]): List of list of tokens as strings\n",
        "        \"\"\"\n",
        "        tokens = self._tokenize(inputs)\n",
        "        if strip_prefix:\n",
        "            # `aux_chars` are known auxiliary characters that are added to tokens\n",
        "            strip_chars = [\"##\", \"Ġ\", \"__\"]\n",
        "            # TODO: Find a better way to identify prefixes. These depend on the model, so cannot be resolved in ModelWrapper.\n",
        "\n",
        "            def strip(s, chars):\n",
        "                for c in chars:\n",
        "                    s = s.replace(c, \"\")\n",
        "                return s\n",
        "\n",
        "            tokens = [[strip(t, strip_chars) for t in x] for x in tokens]\n",
        "\n",
        "        return tokens\n",
        "\n",
        "class SklearnModelWrapper(ModelWrapper):\n",
        "    \"\"\"Loads a scikit-learn model and tokenizer (tokenizer implements\n",
        "    `transform` and model implements `predict_proba`).\n",
        "\n",
        "    May need to be extended and modified for different types of\n",
        "    tokenizers.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, text_input_list, batch_size=None):\n",
        "        encoded_text_matrix = self.tokenizer.transform(text_input_list).toarray()\n",
        "        tokenized_text_df = pd.DataFrame(\n",
        "\n",
        "            # Remove depracated \"get_feature_names() method\"\n",
        "\n",
        "            encoded_text_matrix)\n",
        "        return self.model.predict_proba(tokenized_text_df)\n",
        "\n",
        "    def get_grad(self, text_input):\n",
        "        raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NzO2w7MwRXl8",
      "metadata": {
        "id": "NzO2w7MwRXl8"
      },
      "source": [
        "# Launching our attack"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "nSLtMs8R8X2B",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSLtMs8R8X2B",
        "outputId": "3170c2ef-2962-4725-a70c-8f5a78a14e94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "textattack: Unknown if model of class <class 'sklearn.linear_model._logistic.LogisticRegression'> compatible with goal function <class 'textattack.goal_functions.classification.untargeted_classification.UntargetedClassification'>.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attack(\n",
            "  (search_method): GreedyWordSwapWIR(\n",
            "    (wir_method):  delete\n",
            "  )\n",
            "  (goal_function):  UntargetedClassification\n",
            "  (transformation):  WordSwapEmbedding(\n",
            "    (max_candidates):  50\n",
            "    (embedding):  WordEmbedding\n",
            "  )\n",
            "  (constraints): \n",
            "    (0): WordEmbeddingDistance(\n",
            "        (embedding):  WordEmbedding\n",
            "        (min_cos_sim):  0.5\n",
            "        (cased):  False\n",
            "        (include_unknown_words):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (1): PartOfSpeech(\n",
            "        (tagger_type):  nltk\n",
            "        (tagset):  universal\n",
            "        (allow_verb_noun_swap):  True\n",
            "        (compare_against_original):  True\n",
            "      )\n",
            "    (2): UniversalSentenceEncoder(\n",
            "        (metric):  angular\n",
            "        (threshold):  0.840845057\n",
            "        (window_size):  15\n",
            "        (skip_text_shorter_than_window):  True\n",
            "        (compare_against_original):  False\n",
            "      )\n",
            "    (3): RepeatModification\n",
            "    (4): StopwordModification\n",
            "    (5): InputColumnModification(\n",
            "        (matching_column_labels):  ['premise', 'hypothesis']\n",
            "        (columns_to_ignore):  {'premise'}\n",
            "      )\n",
            "  (is_black_box):  True\n",
            ") \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 1 / 1 / 0 / 2:  20%|██        | 2/10 [00:07<00:29,  3.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 1 ---------------------------------------------\n",
            "[[1 (86%)]] --> [[0 (50%)]]\n",
            "\n",
            "thi tv is awesom i still haven t tri out all of the differ featur as of yet but it s definit worth the [[price]] the onli problem wa that it didn t [[come]] with a remot control in the [[box]] and i had to contact vizio to get one\n",
            "\n",
            "thi tv is awesom i still haven t tri out all of the differ featur as of yet but it s definit worth the [[award]] the onli problem wa that it didn t [[be]] with a remot control in the [[boxes]] and i had to contact vizio to get one\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 2 ---------------------------------------------\n",
            "[[1 (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "awesom pictur and great valu for the price\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 2 / 2 / 0 / 4:  40%|████      | 4/10 [00:07<00:11,  1.93s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 3 ---------------------------------------------\n",
            "[[0 (63%)]] --> [[1 (55%)]]\n",
            "\n",
            "hi the item wa veri good but the deliveri person deliv it down stair itself our hous is in nd floor and we [[had]] to carri the heavi [[mattress]] upstair which wa veri difficult we [[order]] deliveri onli becaus we can t carri the mattress floor up it would be help if thi doesn t happen again\n",
            "\n",
            "hi the item wa veri good but the deliveri person deliv it down stair itself our hous is in nd floor and we [[got]] to carri the heavi [[bed]] upstair which wa veri difficult we [[commands]] deliveri onli becaus we can t carri the mattress floor up it would be help if thi doesn t happen again\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 4 ---------------------------------------------\n",
            "[[1 (95%)]] --> [[[FAILED]]]\n",
            "\n",
            "the pictur color is veri good and oper veri eash simpl direct\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 3 / 2 / 0 / 5:  50%|█████     | 5/10 [00:07<00:07,  1.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 5 ---------------------------------------------\n",
            "[[1 (94%)]] --> [[0 (87%)]]\n",
            "\n",
            "i [[love]] my new crock they are fur line the onli thing is they make a nois when i walk but i don t care i [[love]] them\n",
            "\n",
            "i [[adore]] my new crock they are fur line the onli thing is they make a nois when i walk but i don t care i [[adore]] them\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 3 / 3 / 0 / 6:  60%|██████    | 6/10 [00:10<00:06,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 6 ---------------------------------------------\n",
            "[[0 (87%)]] --> [[[FAILED]]]\n",
            "\n",
            "i bought thi for my son sever of the spring are smush and will not uncoil which mean my son ha to sleep around sever hole the onli option i can see it to cut open the materi and see how the spring are stuck and tri to free them the foam under the top cover is twist thi mattress wa not worth the money i won t buy from thi compani again\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 3 / 4 / 1 / 8:  80%|████████  | 8/10 [00:10<00:02,  1.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 7 ---------------------------------------------\n",
            "[[0 (73%)]] --> [[[FAILED]]]\n",
            "\n",
            "it keep glitch won t hold my wifi have to keep turn it off and on to work bootleg\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 8 ---------------------------------------------\n",
            "[[1 (56%)]] --> [[[SKIPPED]]]\n",
            "\n",
            "purchas thi tv to display my person item for my busi the remot for thi tv turn on my hous televis and my fire place at the same time won t allow me to work freeli on thi one i brought it ha usb port but on the menu itself is show n a thi is complet garbag\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Succeeded / Failed / Skipped / Total] 4 / 5 / 1 / 10: 100%|██████████| 10/10 [00:11<00:00,  1.15s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------- Result 9 ---------------------------------------------\n",
            "[[0 (100%)]] --> [[[FAILED]]]\n",
            "\n",
            "tv came with no remot or screw for the leg call multipl depart within walmart to get a hold of someon and not one person answer return will never buy onlin again\n",
            "\n",
            "\n",
            "--------------------------------------------- Result 10 ---------------------------------------------\n",
            "[[1 (67%)]] --> [[0 (58%)]]\n",
            "\n",
            "i ve had thi tv for month now and it is a nice tv no problem with it [[so]] far satisfi with my purchas\n",
            "\n",
            "i ve had thi tv for month now and it is a nice tv no problem with it [[even]] far satisfi with my purchas\n",
            "\n",
            "\n",
            "\n",
            "+-------------------------------+--------+\n",
            "| Attack Results                |        |\n",
            "+-------------------------------+--------+\n",
            "| Number of successful attacks: | 4      |\n",
            "| Number of failed attacks:     | 5      |\n",
            "| Number of skipped attacks:    | 1      |\n",
            "| Original accuracy:            | 90.0%  |\n",
            "| Accuracy under attack:        | 50.0%  |\n",
            "| Attack success rate:          | 44.44% |\n",
            "| Average perturbed word %:     | 5.64%  |\n",
            "| Average num. words per input: | 36.1   |\n",
            "| Avg num queries:              | 188.22 |\n",
            "+-------------------------------+--------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f0d37870100>,\n",
              " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0d377e8910>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f0d377a5720>,\n",
              " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0d377e8bb0>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f0d377a6a70>,\n",
              " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0d3540e380>,\n",
              " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0d35f3ee30>,\n",
              " <textattack.attack_results.skipped_attack_result.SkippedAttackResult at 0x7f0d35f3d450>,\n",
              " <textattack.attack_results.failed_attack_result.FailedAttackResult at 0x7f0d36438790>,\n",
              " <textattack.attack_results.successful_attack_result.SuccessfulAttackResult at 0x7f0d3643a110>]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Define a wrapper object to function similarly to a pipeline and hold our fitted classifier model\n",
        "# with our fitted vectorizor. The wrapper is engineered to function within the textattack architecture\n",
        "model_wrapper = SklearnModelWrapper(log_reg, stemmed_tfidf_vect_fit)\n",
        "\n",
        "# The textattack architecture functions on textattack.datasets.Dataset objects\n",
        "# The convertor accepts a list of tuples containing inputs and output examples.\n",
        "# For instance, (\"I like this product\", 1) represents a tuple containing an input and output\n",
        "# Thus, we create a list comprehension to compile the df['text'] & df['label'] into this format\n",
        "data = [(df_train['stemmed'][x], int(df_train['label'][x])) for x in range(0,(len(df_train)))]\\\n",
        "# Then we call the textattack converter to assemble our data into the architecture\n",
        "dataset = textattack.datasets.Dataset(data)\n",
        "\n",
        "# The attack recipe in this attack is based on TextFooler, an adversarial attacker on NLP datasets that functions\n",
        "# by trying out iterations of tokens that can be modified slightly to cause the model to misclassify the sentiment\n",
        "# This attacker is pretrained and loaded into textattack libraries, so we can call it and build the adversarial\n",
        "# model based on our NLP model\n",
        "attack = TextFoolerJin2019.build(model_wrapper)\n",
        "# We can specifically add more arguments to the Attacker class, but the pretrained model is optimal as is\n",
        "attacker = Attacker(attack, dataset)\n",
        "# Call .attack_dataset() to create .attack instances across the whole dataset\n",
        "attacker.attack_dataset()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "Yf8K8Y2IRy9o",
        "FWwbIxymRnfk",
        "1ufAhvW6Kz1y",
        "aqz_pFWbKpTO",
        "JOpaJ8CkMGTs",
        "tKwBSmnPNfED",
        "0CaHzmtFRaK3",
        "NzO2w7MwRXl8"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "bootcampDev",
      "language": "python",
      "name": "bootcampdev"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}